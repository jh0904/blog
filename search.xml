<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2F2018%2F07%2F04%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[多线程1:多线程(理解) 多线程：一个应用程序有多条执行路径进程：正在执行的应用程序 线程：进程的执行单元，执行路径 单线程：一个应用程序只有一条执行路径 多线程：一个应用程序有多条执行路径 **多进程的意义?** 提高CPU的使用率 **多线程的意义?** 提高应用程序的使用率 Java程序的运行原理及JVM的启动是多线程的吗? A:Java命令去启动JVM，JVM会启动一个进程，该进程会启动一个主线程。 B:JVM的启动是多线程的，因为它最低有两个线程启动了，主线程和垃圾回收线程。 多线程的实现方案(自己补齐步骤及代码 掌握) A:继承Thread类 B:实现Runnable接口 线程的调度和优先级问题A:线程的调度 a:分时调度 b:抢占式调度 (Java采用的是该调度方式) B:获取和设置线程优先级 a:默认是5 b:范围是1-10 线程的控制(常见方法)A:休眠线程 B:加入线程 C:礼让线程 D:后台线程 E:终止线程(掌握) 线程的生命周期(参照 线程生命周期图解.bmp)A:新建 B:就绪 C:运行 D:阻塞 E:死亡 电影院卖票程序的实现A:继承Thread类 B:实现Runnable接口 电影院卖票程序出问题A:为了更符合真实的场景，加入了休眠100毫秒。 B:卖票问题 a:同票多次 b:负数票 多线程安全问题的原因(也是我们以后判断一个程序是否有线程安全问题的依据)A:是否有多线程环境 B:是否有共享数据 C:是否有多条语句操作共享数据 同步解决线程安全问题 A:同步代码块 synchronized(对象) { 需要被同步的代码; } 这里的锁对象可以是任意对象。 B:同步方法 把同步加在方法上。 这里的锁对象是this C:静态同步方法 把同步加在方法上。 这里的锁对象是当前类的字节码文件对象 回顾以前的线程安全的类A:StringBuffer B:Vector C:Hashtable D:如何把一个线程不安全的集合类变成一个线程安全的集合类 用Collections工具类的方法即可。 JDK5以后的针对线程的锁定操作和释放操作Lock锁 死锁问题的描述和代码体现 生产者和消费者多线程体现(线程间通信问题) 以学生作为资源来实现的 资源类：Student 设置数据类：SetThread(生产者) 获取数据类：GetThread(消费者) 测试类：StudentDemo 代码： A:最基本的版本，只有一个数据。 B:改进版本，给出了不同的数据，并加入了同步机制 C:等待唤醒机制改进该程序，让数据能够实现依次的出现 wait() notify() notifyAll() (多生产多消费) D:等待唤醒机制的代码优化。把数据及操作都写在了资源类中 线程组 线程池 多线程实现的第三种方案]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程面试题]]></title>
    <url>%2F2018%2F07%2F04%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[多线程面试题1、多线程有什么用？一个可能在很多人看来很扯淡的一个问题：我会用多线程就好了，还管它有什么用？在我看来，这个回答更扯淡。所谓”知其然知其所以然”，”会用”只是”知其然”，”为什么用”才是”知其所以然”，只有达到”知其然知其所以然”的程度才可以说是把一个知识点运用自如。OK，下面说说我对这个问题的看法： （1）发挥多核CPU的优势 随着工业的进步，现在的笔记本、台式机乃至商用的应用服务器至少也都是双核的，4核、8核甚至16核的也都不少见，如果是单线程的程序，那么在双核CPU上就浪费了50%，在4核CPU上就浪费了75%。单核CPU上所谓的”多线程”那是假的多线程，同一时间处理器只会处理一段逻辑，只不过线程之间切换得比较快，看着像多个线程”同时”运行罢了。多核CPU上的多线程才是真正的多线程，它能让你的多段逻辑同时工作，多线程，可以真正发挥出多核CPU的优势来，达到充分利用CPU的目的。 （2）防止阻塞 从程序运行效率的角度来看，单核CPU不但不会发挥出多线程的优势，反而会因为在单核CPU上运行多线程导致线程上下文的切换，而降低程序整体的效率。但是单核CPU我们还是要应用多线程，就是为了防止阻塞。试想，如果单核CPU使用单线程，那么只要这个线程阻塞了，比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。 （3）便于建模 这是另外一个没有这么明显的优点了。假设有一个大的任务A，单线程编程，那么就要考虑很多，建立整个程序模型比较麻烦。但是如果把这个大的任务A分解成几个小任务，任务B、任务C、任务D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。 2、创建线程的方式比较常见的一个问题了，一般就是两种： （1）继承Thread类 （2）实现Runnable接口 至于哪个好，不用说肯定是后者好，因为实现接口的方式比继承类的方式更灵活，也能减少程序之间的耦合度，面向接口编程也是设计模式6大原则的核心。 3、start()方法和run()方法的区别只有调用了start()方法，才会表现出多线程的特性，不同线程的run()方法里面的代码交替执行。如果只是调用run()方法，那么代码还是同步执行的，必须等待一个线程的run()方法里面的代码全部执行完毕之后，另外一个线程才可以执行其run()方法里面的代码。 4、Runnable接口和Callable接口的区别有点深的问题了，也看出一个Java程序员学习知识的广度。 Runnable接口中的run()方法的返回值是void，它做的事情只是纯粹地去执行run()方法中的代码而已；Callable接口中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。 这其实是很有用的一个特性，因为多线程相比单线程更难、更复杂的一个重要原因就是因为多线程充满着未知性，某条线程是否执行了？某条线程执行了多久？某条线程执行的时候我们期望的数据是否已经赋值完毕？无法得知，我们能做的只是等待这条多线程的任务执行完毕而已。而Callable+Future/FutureTask却可以获取多线程运行的结果，可以在等待时间太长没获取到需要的数据的情况下取消该线程的任务，真的是非常有用。 5、CyclicBarrier和CountDownLatch的区别两个看上去有点像的类，都在java.util.concurrent下，都可以用来表示代码运行到某个点上，二者的区别在于： （1）CyclicBarrier的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行 （2）CyclicBarrier只能唤起一个任务，CountDownLatch可以唤起多个任务 （3）CyclicBarrier可重用，CountDownLatch不可重用，计数值为0该CountDownLatch就不可再用了 6、Volatile关键字的作用一个非常重要的问题，是每个学习、应用多线程的Java程序员都必须掌握的。理解volatile关键字的作用的前提是要理解Java内存模型，这里就不讲Java内存模型了，可以参见第31点，volatile关键字的作用主要有两个： （1）多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据 （2）代码底层执行不像我们看到的高级语言—-Java程序这么简单，它的执行是Java代码–&gt;字节码–&gt;根据字节码执行对应的C/C++代码–&gt;C/C++代码被编译成汇编语言–&gt;和硬件电路交互，现实中，为了获取更好的性能JVM可能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序，当然这也一定程度上降低了代码执行效率 从实践角度而言，volatile的一个重要作用就是和CAS结合，保证了原子性，详细的可以参见java.util.concurrent.atomic包下的类，比如AtomicInteger。 7、什么是线程安全又是一个理论的问题，各式各样的答案有很多，我给出一个个人认为解释地最好的：如果你的代码在多线程下执行和在单线程下执行永远都能获得一样的结果，那么你的代码就是线程安全的。 这个问题有值得一提的地方，就是线程安全也是有几个级别的： （1）不可变 像String、Integer、Long这些，都是final类型的类，任何一个线程都改变不了它们的值，要改变除非新创建一个，因此这些不可变对象不需要任何同步手段就可以直接在多线程环境下使用 （2）绝对线程安全 不管运行时环境如何，调用者都不需要额外的同步措施。要做到这一点通常需要付出许多额外的代价，Java中标注自己是线程安全的类，实际上绝大多数都不是线程安全的，不过绝对线程安全的类，Java中也有，比方说CopyOnWriteArrayList、CopyOnWriteArraySet （3）相对线程安全 相对线程安全也就是我们通常意义上所说的线程安全，像Vector这种，add、remove方法都是原子操作，不会被打断，但也仅限于此，如果有个线程在遍历某个Vector、有个线程同时在add这个Vector，99%的情况下都会出现ConcurrentModificationException，也就是fail-fast机制。 （4）线程非安全 这个就没什么好说的了，ArrayList、LinkedList、HashMap等都是线程非安全的类 8、Java中如何获取到线程dump文件死循环、死锁、阻塞、页面打开慢等问题，打线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈，获取到线程堆栈有两步： （1）获取到线程的pid，可以通过使用jps命令，在Linux环境下还可以使用ps -ef | grep java （2）打印线程堆栈，可以通过使用jstack pid命令，在Linux环境下还可以使用kill -3 pid 另外提一点，Thread类提供了一个getStackTrace()方法也可以用于获取线程堆栈。这是一个实例方法，因此此方法是和具体线程实例绑定的，每次获取获取到的是具体某个线程当前运行的堆栈， 9、一个线程如果出现了运行时异常会怎么样如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放 10、如何在两个线程之间共享数据通过在线程之间共享对象就可以了，然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待，比方说阻塞队列BlockingQueue就是为线程之间共享数据而设计的 11、sleep方法和wait方法有什么区别这个问题常问，sleep方法和wait方法都可以用来放弃CPU一定的时间，不同点在于如果线程持有某个对象的监视器，sleep方法不会放弃这个对象的监视器，wait方法会放弃这个对象的监视器 12、生产者消费者模型的作用是什么这个问题很理论，但是很重要： （1）通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用 （2）解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约 13、ThreadLocal有什么用简单说ThreadLocal就是一种以空间换时间的做法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了 14、为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用这是JDK强制的，wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁 15、wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。 16、为什么要使用线程池避免频繁地创建和销毁线程，达到线程对象的重用。另外，使用线程池还可以根据项目灵活地控制并发的数目。 17、怎么检测一个线程是否持有对象监视器我也是在网上看到一道多线程面试题才知道有方法可以判断某个线程是否持有对象监视器：Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着“某条线程”指的是当前线程。 18、synchronized和ReentrantLock的区别synchronized是和if、else、for、while一样的关键字，ReentrantLock是类，这是二者的本质区别。既然ReentrantLock是类，那么它就提供了比synchronized更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock比synchronized的扩展性体现在几点上： （1）ReentrantLock可以对获取锁的等待时间进行设置，这样就避免了死锁 （2）ReentrantLock可以获取各种锁的信息 （3）ReentrantLock可以灵活地实现多路通知 另外，二者的锁机制其实也是不一样的。ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word，这点我不能确定。 19、ConcurrentHashMap的并发度是什么ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？ 20、ReadWriteLock是什么首先明确一下，不是说ReentrantLock不好，只是ReentrantLock某些时候有局限。如果使用ReentrantLock，可能本身是为了防止线程A在写数据、线程B在读数据造成的数据不一致，但这样，如果线程C在读数据、线程D也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。 因为这个，才诞生了读写锁ReadWriteLock。ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。 21、FutureTask是什么这个其实前面有提到过，FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然，由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池中。 22、Linux环境下如何查找哪个线程使用CPU最长这是一个比较偏实践的问题，这种问题我觉得挺有意义的。可以这么做： （1）获取项目的pid，jps或者ps -ef | grep java，这个前面有讲过 （2）top -H -p pid，顺序不能改变 这样就可以打印出当前的项目，每条线程占用CPU时间的百分比。注意这里打出的是LWP，也就是操作系统原生线程的线程号，我笔记本山没有部署Linux环境下的Java工程，因此没有办法截图演示，网友朋友们如果公司是使用Linux环境部署项目的话，可以尝试一下。 使用”top -H -p pid”+”jps pid”可以很容易地找到某条占用CPU高的线程的线程堆栈，从而定位占用CPU高的原因，一般是因为不当的代码操作导致了死循环。 最后提一点，”top -H -p pid”打出来的LWP是十进制的，”jps pid”打出来的本地线程号是十六进制的，转换一下，就能定位到占用CPU高的线程的当前线程堆栈了。 23、Java编程写一个会导致死锁的程序第一次看到这个题目，觉得这是一个非常好的问题。很多人都知道死锁是怎么一回事儿：线程A和线程B相互等待对方持有的锁导致程序无限死循环下去。当然也仅限于此了，问一下怎么写一个死锁的程序就不知道了，这种情况说白了就是不懂什么是死锁，懂一个理论就完事儿了，实践中碰到死锁的问题基本上是看不出来的。 真正理解什么是死锁，这个问题其实不难，几个步骤： （1）两个线程里面分别持有两个Object对象：lock1和lock2。这两个lock作为同步代码块的锁； （2）线程1的run()方法中同步代码块先获取lock1的对象锁，Thread.sleep(xxx)，时间不需要太多，50毫秒差不多了，然后接着获取lock2的对象锁。这么做主要是为了防止线程1启动一下子就连续获得了lock1和lock2两个对象的对象锁 （3）线程2的run)(方法中同步代码块先获取lock2的对象锁，接着获取lock1的对象锁，当然这时lock1的对象锁已经被线程1锁持有，线程2肯定是要等待线程1释放lock1的对象锁的 这样，线程1″睡觉”睡完，线程2已经获取了lock2的对象锁了，线程1此时尝试获取lock2的对象锁，便被阻塞，此时一个死锁就形成了。代码就不写了，占的篇幅有点多，Java多线程7：死锁这篇文章里面有，就是上面步骤的代码实现。 24、怎么唤醒一个阻塞的线程如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。 25、不可变对象对多线程有什么帮助前面有提到过的一个问题，不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。 26、什么是多线程的上下文切换多线程的上下文切换是指CPU控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取CPU执行权的线程的过程。 27、如果你提交任务时，线程池队列已满，这时会发生什么如果你使用的LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为LinkedBlockingQueue可以近乎认为是一个无穷大的队列，可以无限存放任务；如果你使用的是有界队列比方说ArrayBlockingQueue的话，任务首先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，则会使用拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy。 28、Java中用到的线程调度算法是什么抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。 29、Thread.sleep(0)的作用是什么这个问题和上面那个问题是相关的，我就连在一起了。由于Java采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到CPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。 30、什么是自旋很多synchronized里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然synchronized里面的代码执行地非常快，不妨让等待锁的线程不要被阻塞，而是在synchronized的边界做忙循环，这就是自旋。如果做了多次忙循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 31、什么是Java内存模型Java内存模型定义了一种多线程访问Java内存的规范。Java内存模型要完整讲不是这里几句话能说清楚的，我简单总结一下Java内存模型的几部分内容： （1）Java内存模型将内存分为了主内存和工作内存。类的状态，也就是类之间共享的变量，是存储在主内存中的，每次Java线程用到这些主内存中的变量的时候，会读一次主内存中的变量，并让这些内存在自己的工作内存中有一份拷贝，运行自己线程代码的时候，用到这些变量，操作的都是自己工作内存中的那一份。在线程代码执行完毕之后，会将最新的值更新到主内存中去 （2）定义了几个原子操作，用于操作主内存和工作内存中的变量 （3）定义了volatile变量的使用规则 （4）happens-before，即先行发生原则，定义了操作A必然先行发生于操作B的一些规则，比如在同一个线程内控制流前面的代码一定先行发生于控制流后面的代码、一个释放锁unlock的动作一定先行发生于后面对于同一个锁进行锁定lock的动作等等，只要符合这些规则，则不需要额外做同步措施，如果某段代码不符合所有的happens-before规则，则这段代码一定是线程非安全的 32、什么是CASCAS，全称为Compare and Set，即比较-设置。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功。 33、什么是乐观锁和悲观锁（1）乐观锁：就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-设置这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。 （2）悲观锁：还是像它的名字一样，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。 34、什么是AQS简单说一下AQS，AQS全称为AbstractQueuedSychronizer，翻译过来应该是抽象队列同步器。 如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等等都用到了它。AQS实际上以双向队列的形式连接所有的Entry，比方说ReentrantLock，所有等待的线程都被放在一个Entry中并连成双向队列，前面一个线程使用ReentrantLock好了，则双向队列实际上的第一个Entry开始运行。 AQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。 35、单例模式的线程安全性老生常谈的问题了，首先要说的是单例模式的线程安全意味着：某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法，我总结一下： （1）饿汉式单例模式的写法：线程安全 （2）懒汉式单例模式的写法：非线程安全 （3）双检锁单例模式的写法：线程安全 36、Semaphore有什么作用Semaphore就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。 37、Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？这是我之前的一个困惑，不知道大家有没有想过这个问题。某个方法中如果有多条语句，并且都在操作同一个类变量，那么在多线程环境下不加锁，势必会引发线程安全问题，这很好理解，但是size()方法明明只有一条语句，为什么还要加锁？ 关于这个问题，在慢慢地工作、学习中，有了理解，主要原因有两点： （1）同一时间只能有一条线程执行固定类的同步方法，但是对于类的非同步方法，可以多条线程同时访问。所以，这样就有问题了，可能线程A在执行Hashtable的put方法添加数据，线程B则可以正常调用size()方法读取Hashtable中当前元素的个数，那读取到的值可能不是最新的，可能线程A添加了完了数据，但是没有对size++，线程B就已经读取size了，那么对于线程B来说读取到的size一定是不准确的。而给size()方法加了同步之后，意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用，这样就保证了线程安全性 （2）CPU执行代码，执行的不是Java代码，这点很关键，一定得记住。Java代码最终是被翻译成汇编代码执行的，汇编代码才是真正可以和硬件电路交互的代码。即使你看到Java代码只有一行，甚至你看到Java代码编译之后生成的字节码也只有一行，也不意味着对于底层来说这句语句的操作只有一个。一句”return count”假设被翻译成了三句汇编语句执行，完全可能执行完第一句，线程就切换了。 38、线程类的构造方法、静态块是被哪个线程调用的这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被new这个线程类所在的线程所调用的，而run方法里面的代码才是被线程自身所调用的。 如果说上面的说法让你感到困惑，那么我举个例子，假设Thread2中new了Thread1，main函数中new了Thread2，那么： （1）Thread2的构造方法、静态块是main线程调用的，Thread2的run()方法是Thread2自己调用的 （2）Thread1的构造方法、静态块是Thread2调用的，Thread1的run()方法是Thread1自己调用的 39、同步方法和同步块，哪个是更好的选择同步块，这意味着同步块之外的代码是异步执行的，这比同步整个方法更提升代码的效率。请知道一条原则：同步的范围越少越好。 借着这一条，我额外提一点，虽说同步的范围越少越好，但是在Java虚拟机中还是存在着一种叫做锁粗化的优化方法，这种方法就是把同步范围变大。这是有用的，比方说StringBuffer，它是一个线程安全的类，自然最常用的append()方法是一个同步方法，我们写代码的时候会反复append字符串，这意味着要进行反复的加锁-&gt;解锁，这对性能不利，因为这意味着Java虚拟机在这条线程上要反复地在内核态和用户态之间进行切换，因此Java虚拟机会将多次append方法调用的代码进行一个锁粗化的操作，将多次的append的操作扩展到append方法的头尾，变成一个大的同步块，这样就减少了加锁–&gt;解锁的次数，有效地提升了代码执行的效率。 40、高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？这是我在并发编程网上看到的一个问题，把这个问题放在最后一个，希望每个人都能看到并且思考一下，因为这个问题非常好、非常实际、非常专业。关于这个问题，个人看法是： （1）高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换 （2）并发不高、任务执行时间长的业务要区分开看： a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以加大线程池中的线程数目，让CPU处理更多的业务 b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换 （3）并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）。最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识NIO一]]></title>
    <url>%2F2018%2F06%2F22%2FNIO%2F</url>
    <content type="text"><![CDATA[NIO概述 [name=magic] Java NIO（New IO） 是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同， NIO支持面向缓冲区的、基于通道的IO操作。 NIO将以更加高效的方式进行文件的读写操作。 JDK之后的NIO：也叫做NIO2（BIO） Path：路径（与平台无关） Paths：有一个静态方法返回路径（返回Path的静态方法） public static Path get(URI uri); Files：提供静态方法（操作文件的工具类） public static long copy(Path source, OutputStream out) 将文件中的所有字节复制到输出流。 public static Path write(Path path, Iterable lines, Charset cs, OpenOption... options) 将文本行写入文件。 NIO与IO区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 通道和缓冲区 Java NIO系统的核心在于：通道(Channel)和(Buffer)。通道表示打开到 IO 设备(例如：套接字)的连接。若需要使用 NIO 系统，需用于连接 IO 设备的通道以及用于容纳数据区。然后操作缓冲区，对数据进行处理 简而言之， Channel 负责传输， Buffer 负责存储 NIO缓冲区（Buffer） 缓冲区概述 缓冲区（Buffer） ：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类 Java NIO 中的 Buffer 主要用于与 NIO 通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的 Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。 都是通过如下方法获取一个 Buffer对象： static XxxBuffer allocate(int capacity) : 创建一个容量为 capacity 的 XxxBuffer 对象 Buffer 中的重要概念： 容量 (capacity) ： 表示 Buffer 最大数据容量，缓冲区容量不能为负，并且创建后不能更改。 限制 (limit)： 第一个不应该读取或写入的数据的索引，即位于 limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 位置 (position)： 下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制 标记 (mark)与重置 (reset)： 标记是一个索引，通过 Buffer 中的 mark() 方法指定 Buffer 中一个特定的 position，之后可以通过调用 reset() 方法恢复到这个 position 并且 0 &lt; mark &lt;= position &lt;=limit &lt;= capacity 1. 分配一个缓冲区要获得一个Buffer对象，你必须首先分配它，通过allocate()分配了一个10字节大小的缓冲区。 12ByteBuffer buf = ByteBuffer.allocate(10); 2. 将数据写入缓冲区将数据写入缓冲区有两种方式： 1.利用 put() 存入数据到缓冲区中 1234String str = "abcde";buf.put(str.getBytes()); put的方法总结put(byte b)：将给定单个字节写入缓冲区的当前位置put(byte[] src)：将 src 中的字节写入缓冲区的当前位置put(int index, byte b)：将指定字节写入缓冲区的索引位置(不会移动 position) 2.将数据从 Channel写入Buffer 1234int bytesRead = inChannel.read（buf）;//读入缓冲区。 3. filp() 该flip()方法将Buffer从写入模式切换到读取模式。调用flip()将position设置为0，并将其设置为limit 刚才的位置。 换句话说，position现在标记了读取位置，并limit标记了多少字节，字符等被写入缓冲区,可以读取的字节数，字节数等限制。 12buf.flip(); 4. 从缓冲区读取数据有两种方法可以从Buffer中读取数据。 1.将数据从缓冲区读入通道。 1234//从缓冲区读入通道。int bytesWritten = inChannel.write（buf）; 2.使用其中一个get（）方法自己从缓冲区中读取数据。 123456byte[] dst = new byte[buf.limit()];buf.get(dst);System.out.println(new String(dst, 0, dst.length)); get的一些方法总结get() ：读取单个字节get(byte[] dst)：批量读取多个字节到 dst 中get(int index)：读取指定索引位置的字节(不会移动 position) 5. rewind()Buffer.rewind() 让 position 返回到0,这样你就可以重新读取缓冲区中的所有数据。在limit保持不变，因此仍然标记多少个元素（字节，字符等），可以从被读取Buffer。 6. clear（）和compact（）一旦你完成了读取数据，Buffer 准备好再次写入。你可以通过调用clear()或调用compact()。 如果调用clear（），则position将设置回0并且limit会变成capacity。, 换句话说，缓冲区被清除,但是缓冲区中的数据未被清除。, 只有markers告诉您可以将数据写入缓冲区的位置。 如果在调用clear（）时缓冲区中存在未读取的数据，那么数据将处于“forgotten”，这意味着不再有任何标记，指示已读取的数据以及尚未读取的数据。 如果Buffer中仍有未读数据，并且想稍后read，需要先写一些内容，调用compact（）而不是clear（）。 compact（）将所有未读数据复制到缓冲区的开始处。, 然后它将position设置在最后一个未读元素之后。, 极限属性仍然设置为容量，就像clear（）一样。, 现在缓冲区已准备好写入，但不会覆盖未读数据。 7. mark（）和reset（）可以通过调用Buffer.mark()方法在Buffer中标记给定的位置。然后可以通过调用该Buffer.reset() 方法将位置重新设置回标记的位置。 1234567891011121314151617181920212223242526272829303132 String str = "abcde";ByteBuffer buf = ByteBuffer.allocate(1024);buf.put(str.getBytes());buf.flip();byte[] dst = new byte[buf.limit()];buf.get(dst, 0, 2);System.out.println(new String(dst, 0, 2));System.out.println(buf.position());//mark() : 标记buf.mark();buf.get(dst, 2, 2);System.out.println(new String(dst, 2, 2));System.out.println(buf.position());//reset() : 恢复到 mark 的位置buf.reset();System.out.println(buf.position()); 8. equals（）和compareTo（）可以使用equals（）和compareTo（）来比较两个缓冲区 equals() 它们是相同的类型（byte，char，int等） 它们在缓冲区中具有相同数量的剩余字节，字符等。 所有剩余的字节，字符等是相等的。 正如你所看到的，equals只比较缓冲区的一部分，而不是它内部的每一个元素。, 实际上，它只是比较缓冲区中的其余元素。 compareTo() 该compareTo()方法比较两个缓冲区的其余元素（字节，字符等），用于例如排序例程。在下列情况下，缓冲区被认为比另一个缓冲区“小” 第一个元素等于另一个缓冲区中的对应元素，小于另一个缓冲区中的元素。 所有的元素都是相等的，但第一个缓冲区在第二个缓冲区之前耗尽元素（元素较少）。 直接与非直接缓冲区非直接缓冲区：通过 allocate() 方法分配缓冲区，将缓冲区建立在 JVM 的内存中。直接缓冲区：通过 allocateDirect() 方法分配直接缓冲区，将缓冲区建立在物理内存中。可以提高效率。 字节缓冲区要么是直接的，要么是非直接的。如果为直接字节缓冲区，则 Java 虚拟机会尽最大努力直接在此缓冲区上执行本机 I/O 操作。也就是说，在每次调用基础操作系统的一个本机 I/O 操作之前（或之后），虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中（或从中间缓冲区中复制内容）。 直接字节缓冲区可以通过调用此类的 allocateDirect() 工厂方法来创建。此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。 直接字节缓冲区还可以通过 FileChannel 的 map() 方法 将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer 。 Java 平台的实现有助于通过 JNI 从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。 字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect() 方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理。非直接缓冲区：直接缓冲区： NIO通道(Channel) 概述通道（Channel）：由 java.nio.channels 包定义的。 Channel 表示 IO 源与目标打开的连接。Channel 类似于传统的“流”。只不过 Channel本身不能直接访问数据， Channel 只能与Buffer 进行交互。 通道和流的区别通道有点类似于流，但是还是有一些区别的： 流是单向的，或者输出流或是输入流，而通道是双向的。 通道可以被异步读取和写入。 通道始终读取或写入缓冲区。 总的来说可以把之前学习的的流想象成水流，数据通过水流去传输，或是往上流或者往下流（单向）。可以把通道想象成轨道，轨道本身不拥有数据，其中数据的传输是依靠火车（也就是缓冲区）来传输数据。并且双向都可。 Channel实现类 FileChannel：用于读取、写入、映射和操作文件的通道。 DatagramChannel：通过 UDP 读写网络中的数据通道。 SocketChannel：通过 TCP 读写网络中的数据。 ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。 获取通道获取通道的一种方式是对支持通道的对象调用getChannel() 方法。支持通道的类如下： FileInputStream FileOutputStream RandomAccessFile DatagramSocket Socket ServerSocket 获取通道的其他方式是使用 Files 类的静态方法 newByteChannel() 获取字节通道。或者通过通道的静态方法 open() 打开并返回指定通道。 将 Buffer 中数据写入 Channel 12//将Buffer中数据写入Channel中int bytesWritten = inChannel.write(buf); 从 Channel 读取数据到 Buffer 12//从Channel中读取数据到Bufferint bytesRead = inChannel.read(buf); 两个例子： 1.利用通道复制文件（非直接缓冲区）123456789101112131415161718192021222324252627282930313233public void test1() throws IOException &#123; FileInputStream fis = new FileInputStream ("d:/aa.mkv"); FileOutputStream fos = new FileOutputStream ("d:/11.mkv"); //1.获取通道 FileChannel fisChannel = fis.getChannel (); FileChannel fosChannel = fos.getChannel (); //2.分配指定大小缓冲区 ByteBuffer buffer = ByteBuffer.allocate (1024); //3.将同道中的数据存入缓冲区 while (fisChannel.read (buffer) != -1) &#123; buffer.flip ();//切换成读数据模式 //4.将缓冲区数据写入通道 fosChannel.write (buffer); buffer.clear ();//清空缓冲区 &#125; if (fosChannel != null) &#123; fosChannel.close (); &#125; if (fisChannel != null) &#123; fisChannel.close (); &#125; if (fos != null) &#123; fos.close (); &#125; if (fis != null) &#123; fis.close (); &#125;&#125; 2.利用直接缓冲区（只有ByteBuffer支持）完成文件的复制（内存映射文件） 123456789101112131415161718192021public void test2() throws IOException &#123; FileChannel inChannel = FileChannel.open(Paths.get("d:/aa.mkv"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get("d:/2.mkv"), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); /* * StandardOpenOption.CREATE-----------&gt;不存在就创建，存在就覆盖 * StandardOpenOption.CREATE_NEW-----------&gt;不存在就创建，存在就报错 */ //内存映射文件 MappedByteBuffer inMappedBuf = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); MappedByteBuffer outMappedBuf = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size()); //直接对缓冲区进行读写操作 byte[] dst = new byte[inMappedBuf.limit()]; inMappedBuf.get(dst); outMappedBuf.put(dst); inChannel.close(); outChannel.close(); &#125; 分散(Scatter)和聚集(Gather)分散读取（Scattering Reads）分散读取（Scattering Reads）是指从 Channel 中读取的数据“分散” 到多个 Buffer 中.具体代码参考下例： 注意：按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满 聚集写入(Gathering Writers)聚集写入（Gathering Writes）是指将多个 Buffer 中的数据“聚集”到 Channel。按照顺序写入通道中。 1234567891011121314151617181920212223public void test4() throws IOException &#123; RandomAccessFile file = new RandomAccessFile ("aa.txt", "rw"); //获取通道 FileChannel channel = file.getChannel (); //分配指定大小缓冲区 ByteBuffer buffer = ByteBuffer.allocate (100); ByteBuffer buffer1 = ByteBuffer.allocate (1024); //分散读取 ByteBuffer[] buf = &#123;buffer, buffer1&#125;; channel.read (buf); for (ByteBuffer byteBuffer : buf) &#123; byteBuffer.flip (); &#125; System.out.println (new String (buf[0].array (), 0, buf[0].limit ())); System.out.println ("--------------------------------------------------------"); System.out.println (new String (buf[1].array (), 0, buf[1].limit ())); //聚集写入 RandomAccessFile rw = new RandomAccessFile ("hy.txt", "rw"); FileChannel channel1 = rw.getChannel (); channel1.write (buf); &#125; 字符集（CharSet）编码：字符串 —-&gt;字符数组。解码：字符数组—-&gt;字符串。首先常见的字符集有UTF-8和GBK。解码有一个思想，就是用什么编码， 用什么解码，就不会乱码。出现乱码肯定是因为编码和解码的码制不一样。 首先了解都有什么码制,Charset就是java中码制的类。 1234567public void test5() &#123; SortedMap&lt;String, Charset&gt; stringCharsetSortedMap = Charset.availableCharsets (); Set&lt;Map.Entry&lt;String, Charset&gt;&gt; entries = stringCharsetSortedMap.entrySet (); for (Map.Entry&lt;String, Charset&gt; entry : entries) &#123; System.out.println (entry.getKey () + "---" + entry.getValue ()); &#125; &#125; 用NIO实现编码和解码 这个就是先用GBK进行编码和解码。没有乱码问题，但是用UTF-8进行解码。就出现了乱码。所以说，解决乱码的根本途径就是编码和解码一致。123456789101112131415161718192021222324252627282930public void test6() throws CharacterCodingException &#123; Charset gbk = Charset.forName ("GBK"); //获取编码器 CharsetEncoder ce = gbk.newEncoder (); //获取解码器 CharsetDecoder cd = gbk.newDecoder (); CharBuffer allocate = CharBuffer.allocate (1024); allocate.put ("爱生活爱java"); allocate.flip (); //编码 ByteBuffer encode = ce.encode (allocate); for (int i = 0; i &lt; 12; i++) &#123; System.out.println (encode.get ()); &#125; //解码 encode.flip (); CharBuffer decode = cd.decode (encode); System.out.println (decode.toString ()); System.out.println ("------------------------"); encode.flip (); Charset utf = Charset.forName ("UTF-8"); CharBuffer decode1 = utf.decode (encode); System.out.println (decode1.toString ()); &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql必知必会（连接，查询，排序）]]></title>
    <url>%2F2018%2F06%2F10%2FMysql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%EF%BC%88%E8%BF%9E%E6%8E%A5%EF%BC%8C%E6%A3%80%E7%B4%A2%EF%BC%8C%E6%8E%92%E5%BA%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Mysql必知必会（连接，检索，排序）分别对应Mysql必知必会3,4,5章节的内容。下面做简单的示例。 连接数据库和进入 连接数据123456mysql -u ben //以ben用户进入数据库 mysql -uroot -proot -h localhost -P 3306 //以root用户，root密码，本地ip，端口号3306进入mysql。mysql -uroot -proot //默认本地，3306登录。 登录成功页面： 选择数据库 SHOW DATABASES; //显示所有表空间1234567891011121314151617mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || demo || exam || how2java || jh || magic || mysql || performance_schema || root || ssh || test |+--------------------+11 rows in set (0.00 sec) USE jh //使用jh数据库表空间 12mysql&gt; use jh;Database changed show tables; //显示jh数据库中有哪些表123456789101112131415mysql&gt; show tables;+--------------+| Tables_in_jh |+--------------+| category || customers || knowledge || orderitems || orders || productnotes || products || user || vendors |+--------------+9 rows in set (0.00 sec) SHOW COLUMNS FROM customers//查看表结构123456789101112131415mysql&gt; SHOW COLUMNS FROM customers;+--------------+-----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+-----------+------+-----+---------+----------------+| cust_id | int(11) | NO | PRI | NULL | auto_increment || cust_name | char(50) | NO | | NULL | || cust_address | char(50) | YES | | NULL | || cust_city | char(50) | YES | | NULL | || cust_state | char(5) | YES | | NULL | || cust_zip | char(10) | YES | | NULL | || cust_country | char(50) | YES | | NULL | || cust_contact | char(50) | YES | | NULL | || cust_email | char(255) | YES | | NULL | |+--------------+-----------+------+-----+---------+----------------+9 rows in set (0.01 sec) 其实还有一些数据库的show语句： SHOW STATUS; //显示服务器状态 SHOW CREATE DATABASE || SHOW CREATE TABLE; //显示特定数据库或表的语句 SHOW GRANTS; //显示授权用户的安全权限 SHOW ERROR || SHOW WARNINGS; //显示服务器错误和警告 DESC product;查看表结构1234567891011mysql&gt; DESC products;+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| prod_id | char(10) | NO | PRI | NULL | || vend_id | int(11) | NO | MUL | NULL | || prod_name | char(255) | NO | | NULL | || prod_price | decimal(8,2) | NO | | NULL | || prod_desc | text | YES | | NULL | |+------------+--------------+------+-----+---------+-------+5 rows in set (0.01 sec) 数据库的查询select语句是用来从数据库中查询的语句，也是最重要的语句。简单的说一下sql语句的一些要求: 结束sql语句，用(;)号隔开；多条语句也是。 SQL语句不区分大小写，但是尽量在SQL关键字的时候使用大写，便于阅读和区分。 处理SQL语句的时候，其中所有的空格都被忽略，可以把所有语句写在一行，但是便于阅读，尽量分行写。检索单个列 SELECT prod_name FROM products; 这个语句就是检索products中的 prod_name 这一列。12345678910111213141516171819+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed || Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 检索多个列 select prod_id,prod_name,prod_price from products; 这个语句就是检索products中的 prod_name,prod_name,prod_price 三列。1234567891011121314151617181920mysql&gt; select prod_id,prod_name,prod_price from products;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| ANV01 | .5 ton anvil | 5.99 || ANV02 | 1 ton anvil | 9.99 || ANV03 | 2 ton anvil | 14.99 || DTNTR | Detonator | 13.00 || FB | Bird seed | 10.00 || FC | Carrots | 2.50 || FU1 | Fuses | 3.42 || JP1000 | JetPack 1000 | 35.00 || JP2000 | JetPack 2000 | 55.00 || OL1 | Oil can | 8.99 || SAFE | Safe | 50.00 || SLING | Sling | 4.49 || TNT1 | TNT (1 stick) | 2.50 || TNT2 | TNT (5 sticks) | 10.00 |+---------+----------------+------------+14 rows in set (0.00 sec) 检索所有列这个使用了通配符（*），这个代表所有的意思。 select * from products; 检索products的所有信息。1234567891011121314151617181920mysql&gt; select * from products;+---------+---------+----------------+------------+----------------------------------------------------------------+| prod_id | vend_id | prod_name | prod_price | prod_desc |+---------+---------+----------------+------------+----------------------------------------------------------------+| ANV01 | 1001 | .5 ton anvil | 5.99 | .5 ton anvil, black, complete with handy hook || ANV02 | 1001 | 1 ton anvil | 9.99 | 1 ton anvil, black, complete with handy hook and carrying case || ANV03 | 1001 | 2 ton anvil | 14.99 | 2 ton anvil, black, complete with handy hook and carrying case || DTNTR | 1003 | Detonator | 13.00 | Detonator (plunger powered), fuses not included || FB | 1003 | Bird seed | 10.00 | Large bag (suitable for road runners) || FC | 1003 | Carrots | 2.50 | Carrots (rabbit hunting season only) || FU1 | 1002 | Fuses | 3.42 | 1 dozen, extra long || JP1000 | 1005 | JetPack 1000 | 35.00 | JetPack 1000, intended for single use || JP2000 | 1005 | JetPack 2000 | 55.00 | JetPack 2000, multi-use || OL1 | 1002 | Oil can | 8.99 | Oil can, red || SAFE | 1003 | Safe | 50.00 | Safe with combination lock || SLING | 1003 | Sling | 4.49 | Sling, one size fits all || TNT1 | 1003 | TNT (1 stick) | 2.50 | TNT, red, single stick || TNT2 | 1003 | TNT (5 sticks) | 10.00 | TNT, red, pack of 10 sticks |+---------+---------+----------------+------------+----------------------------------------------------------------+14 rows in set (0.00 sec) 检索不同行比如我们要查询的数据中，有多个重复的数据，我们只想要不同的数据。 select vend_id from products; 1234567891011121314151617181920mysql&gt; select vend_id from products;+---------+| vend_id |+---------+| 1001 || 1001 || 1001 || 1002 || 1002 || 1003 || 1003 || 1003 || 1003 || 1003 || 1003 || 1003 || 1005 || 1005 |+---------+14 rows in set (0.00 sec) 很明显很多数据是无用的。我们现在要来剔除这些重复。我们要使用这个关键字：distinct；要注意的是不能同时使用distinct限制多行， select distinct vend_id，prod_price from products; select distinct vend_id from products;除非两列都相同，否则都会被查出来。 12345678910mysql&gt; select distinct vend_id from products;+---------+| vend_id |+---------+| 1001 || 1002 || 1003 || 1005 |+---------+4 rows in set (0.00 sec) 限制结果(分页) select prod_name from products limit 0,5; 1234567891011mysql&gt; select prod_name from products limit 0,5;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed |+--------------+5 rows in set (0.00 sec) 其中 0是开始位置，5是显示长度。 数据排序排序数据 select prod_name from products order by prod_name; 把查询到的数据按照prod_name排序。1234567891011121314151617181920mysql&gt; select prod_name from products order by prod_name;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Bird seed || Carrots || Detonator || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 多个序列排序 select prod_id,prod_price,prod_name from products order by prod_price,prod_name; 这个例子其实要这样子理解，就是只有在prod_price有相同的情况下，然后取按照prod_name排序。 1234567891011121314151617181920mysql&gt; select prod_id,prod_price,prod_name from products order by prod_price,prod_name;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| FC | 2.50 | Carrots || TNT1 | 2.50 | TNT (1 stick) || FU1 | 3.42 | Fuses || SLING | 4.49 | Sling || ANV01 | 5.99 | .5 ton anvil || OL1 | 8.99 | Oil can || ANV02 | 9.99 | 1 ton anvil || FB | 10.00 | Bird seed || TNT2 | 10.00 | TNT (5 sticks) || DTNTR | 13.00 | Detonator || ANV03 | 14.99 | 2 ton anvil || JP1000 | 35.00 | JetPack 1000 || SAFE | 50.00 | Safe || JP2000 | 55.00 | JetPack 2000 |+---------+------------+----------------+14 rows in set (0.00 sec) 正序，倒序 select prod_id,prod_price,prod_name from products order by prod_price DESC; 其中DESC是倒序的意思，升序就是ASC，但是ASC没有多大作用，因为默认就是ASC的1234567891011121314151617181920mysql&gt; select prod_id,prod_price,prod_name from products order by prod_price DESC;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| JP2000 | 55.00 | JetPack 2000 || SAFE | 50.00 | Safe || JP1000 | 35.00 | JetPack 1000 || ANV03 | 14.99 | 2 ton anvil || DTNTR | 13.00 | Detonator || TNT2 | 10.00 | TNT (5 sticks) || FB | 10.00 | Bird seed || ANV02 | 9.99 | 1 ton anvil || OL1 | 8.99 | Oil can || ANV01 | 5.99 | .5 ton anvil || SLING | 4.49 | Sling || FU1 | 3.42 | Fuses || FC | 2.50 | Carrots || TNT1 | 2.50 | TNT (1 stick) |+---------+------------+----------------+14 rows in set (0.00 sec) 排序小结排序是不区分大小写的，对于sql语句来说，A和a的一样的。其实可以用order by 和 limit混合来使用。比如，查询最高价格。 select * from products order by prod_price DESC limit 1; 1234567mysql&gt; select * from products order by prod_price DESC limit 1;+---------+---------+--------------+------------+-------------------------+| prod_id | vend_id | prod_name | prod_price | prod_desc |+---------+---------+--------------+------------+-------------------------+| JP2000 | 1005 | JetPack 2000 | 55.00 | JetPack 2000, multi-use |+---------+---------+--------------+------------+-------------------------+1 row in set (0.00 sec)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解SQL]]></title>
    <url>%2F2018%2F06%2F10%2FMysql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%EF%BC%881%2C2%E7%AB%A0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[了解SQL1.DBMS数据库管理系统 数据库（database） 保存有组织的数据容器。DBMS是操纵和创建数据库的软件，不能直接访问数据库，是通过DBMS去访问。 表（table） 某种特定类型数据的结构化清单。一个结构化的文件，用来存储某种特定类型的数据。 模式（schema） 关于数据库和表的布局以及特征的信息 列（column） 表中的一个字段。所有的表都是由多个或一个列组成的。可以把它想象成一个网格，网格中每个列存储着一条特定的信息。 数据类型（datatype） 所容许的数据类型，它限制列中存储的数据。 行（row） 表中的一个记录。表中的行数也为记录的总数。 主键（primary key） 一列（或一组列），其值能够唯一区分表中的每个行。 ++主键的规范++： 任意两行都不能具有相同的主键值。每个行都必须具有一个主键值（主键不允许为NULL）。 2.什么是SQL?SQL是结构化查询语言（Structured Query Language），是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件的扩展名。SQL的优点： SQL不是某个特定的数据库专用的语言，几乎所有的DBMS都支持SQL。 SQL简单易学，语句描述性很强。 SQL看上去很简单，但是是一个强有力的语言，可以进行很复杂的数据库操作。 3.MySQL简述 MySQL是一个小型关系型数据库管理系统，开发者为瑞典MySQL AB公司，现在已经被Sun公司收购，支持FreeBSD、Linux、MAC、Windows等多种操作系统与其他的大型数据库例如Oracle、DB2、SQL Server等相比功能稍弱一些。其特点有： 1、可以处理拥有上千万条记录的大型数据； 2、支持常见的SQL语句规范； 3、可移植行高，安装简单小巧； 4、良好的运行效率，有丰富信息的网络支持； 5、调试、管理，优化简单（相对其他大型数据库）。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap的源码解析]]></title>
    <url>%2F2018%2F06%2F08%2Fhashmap%2F</url>
    <content type="text"><![CDATA[HashMap的源码解析HashMap的概述HashMap是常用的Java集合之一，是基于哈希表的Map接口的实现。由于HashMap不是线程安全的，如果想要线程安全，可以使用ConcurrentHashMap代替。 API里面给的解释是： 基于哈希表的 Map 接口的实现。此实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap的继承体系我们要了解一个类，首先要了解一下他的继承结构，，才能更好的理解这个类。 123public class HashMap&lt;K,V&gt;extends AbstractMap&lt;K,V&gt;implements Map&lt;K,V&gt;,Cloneable, Serializable 我们可以看一下继承图。这里我们要注意HashMap和Hashtable的继承是不一样的，Hashtable继承的是Dictionary。 大概介绍一下HashMap和Hashtable， HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 HashMap的数据结构从结构实现来讲，HashMap 是数组+链表+红黑树给大家一个图可以更加直观的了解其结构 我们其实还要想，到底是在底层是怎样存储的？为什么这样存，或者说有什么优点？ 我们能从上图看出来，首先是一个数组的存储,查看源码可知，有一个很重要的数组，Node&lt;K,V&gt;[] table，很明显，它是一个Node数组，我们来看一下Node的结构。123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 2.HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码：1hs.put(1,&quot;magic&quot;); 系统将调用”1”这个key的hashCode()方法得到其hashCode 值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。不会都加到一个下标下面的链表去。保证每一个的分散性、均匀性。要做到雨露均沾。 如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。 那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的==Hash算法==和==扩容机制==。 在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子 int modCount; int size; 12345678910111213141516171819202122在 HashMap 中定义了几个常量:static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64; 依次解释一下上面的变量：1. DEFAULT_INITIAL_CAPACITY: 初始容量，也就是默认会创建 16 个箱子，箱子的个数不能太多或太少。如果太少，很容易触发扩容，如果太多，遍历哈希表会比较慢。2. MAXIMUM_CAPACITY:哈希表最大容量，一般情况下只要内存够用，哈希表不会出现问题。3. DEFAULT_LOAD_FACTOR:默认的负载因子。因此初始情况下，当键值对的数量大于 16 * 0.75 = 12 时，就会触发扩容。4. TREEIFY_THRESHOLD:上文说过，如果哈希函数不合理，即使扩容也无法减少箱子中链表的长度，因此 Java 的处理方案是当链表太长时，转换成红黑树。这个值表示当某个箱子中，链表长度大于 8 时，有可能会转化成树。5. UNTREEIFY_THRESHOLD:在哈希表扩容时，如果发现链表长度小于 6，则会由树重新退化为链表。6. MIN_TREEIFY_CAPACITY:在转变成树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换。这是为了避免在哈希表建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。 首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，++扩容后的HashMap容量是之前容量的两倍++。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量（数组中现有的元素）。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中，++哈希桶数组table的长度length大小必须为2的n次方(一定是合数)++，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考http://blog.csdn.net/liuqiyao_01/article/details/14475159，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，==在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。==而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考http://blog.csdn.net/v_july_v/article/details/6105630。 HashMap的功能实现-方法HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。 1. 确定哈希桶数组索引位置不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):12345678910111213141516方法一：static final int hash(Object key) &#123; //jdk1.8 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//jdk1.7static int hash(int h) &#123; h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。下面举例说明下，n为table的长度。 2. 分析HashMap的put方法HashMap的put方法执行过程可以通过下图来理解.①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); &#125; //从put()进入putVal(hash(key), key, value, false, true)；final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 3. 扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。12345678910111213void resize(int newCapacity) &#123; //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor);//修改阈值 &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125;&#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，++所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。++看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，++由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。++有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold初始容量被放入阈值 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults零初始阈值表示使用默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 线程安全性(待深入)在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)： 1234567891011121314151617181920public class HashMapInfiniteLoop &#123; private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); public static void main(String[] args) &#123; map.put(5， &quot;C&quot;); new Thread(&quot;Thread1&quot;) &#123; public void run() &#123; map.put(7, &quot;B&quot;); System.out.println(map); &#125;; &#125;.start(); new Thread(&quot;Thread2&quot;) &#123; public void run() &#123; map.put(3, &quot;A); System.out.println(map); &#125;; &#125;.start(); &#125; &#125; 其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。 线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。 JDK1.8与JDK1.7的性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。 Hash较均匀的情况为了便于测试，我们先写一个类Key，如下： 123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125; 这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下： 123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125; 现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下： 1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125; 在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下： 通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。 Hash极不均匀的情况假设我们又一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下：123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125; 仍然执行main方法，得出的结果如下表所示：从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。 测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。 小结(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。 (2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 (3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。 (4) JDK1.8引入红黑树大程度优化了HashMap的性能。 (5) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于String的理解]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%85%B3%E4%BA%8EString%E7%B1%BB%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[关于下面的代码，为什么结果为true？在我们的想法里，String是一个引用类型，为什么对象可以相等？12345678910111213141516package cn.lq.demo;public class StringDemo &#123; /** * @author magic_jh * @version 1.1.0 */ public static void main(String[] args) &#123; String s1="helloworld"; String s2="helloworld"; String s3=new String("helloworld"); System.out.println(s1==s2);//true System.out.println(s1==s3);//false &#125;&#125; 其实可以看一下内存的分配，就一目了然了。 从图中可以看出其实s1和s2指向的不是堆内存，而是方法区的字符常量池，所以我们知道==比的是地址值，s1,s2指向的是同一个地址，肯定结果为true。我们现在来看s3，s3使用的是构造方法，它就在堆内存开辟了一个空间，其中的”helloworld”还是来自于字符常量池。所以s3指向的是堆内存中的地址，最后与s1比较的是s3指向的地址是堆内存的地址，所以为false。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的操作示例]]></title>
    <url>%2F2018%2F06%2F06%2Fjh0904%2F</url>
    <content type="text"><![CDATA[magic_jh第一次测试三级标题 列表1 列表2 a子列表 b子列表 c子列表 列表3 列表4 jh 字体是斜体 字体加粗 123public static void main(String[] args)&#123;asdas&#125; 我的内容是引用]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vector的源码解析]]></title>
    <url>%2F2018%2F06%2F06%2FVector%E7%9A%84%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Vector源码解析1. Vector概述及继承体系Vector 类可以实现可增长的对象数组。与数组一样，它包含可以使用整数索引进行访问的组件。与新 collection 实现不同，Vector 是同步的。 看一下Vector的继承体系：12public class Vector&lt;E&gt;extends AbstractList&lt;E&gt;implements List&lt;E&gt;, RandomAccess, Cloneable, Serializable RandomAccess接口是在源码中的注释如下： Marker interface used by List implementations to indicate that theysupport fast (generally constant time) random access. 翻译下就是：这是一个标记性的接口，谁实现了这个接口就表明他具有快速随机访问的能力。 2. Vector属性capacityIncrement：自动扩容的大小，即当数组满了之后，就添加capacityIncrement个空间装载元素，如果capacityIncrement&lt;=0,则扩容时就扩容到目前Vector容量的两倍。 elementCount:记录数组中数据的个数。 elementData:数组，因为Vector底层也是数组存储的，所以用这个来存储数据。 123protected int capacityIncrement; //扩容大小protected int elementCount; //数组数据条数protected Object[] elementData; //数组 3. Vector构造方法 Vector构造方法有四个构造方法 3.1.Vector()构造一个空向量，使其内部数据数组的大小为 10，其标准容量增量为零。123public Vector() &#123; this(10);//这里的this调用的是Vector(int initialCapacity) 方法 &#125; 3.2.Vector(Collection &lt;\?extends E&gt; c)构造一个包含指定 collection 中的元素的向量，这些元素按其 collection 的迭代器返回元素的顺序排列。123456789 public Vector(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) //c.toArray可能（不正确）不返回Object []（参见6260652） if (elementData.getClass() != Object[].class)`````` elementData = Arrays.copyOf(elementData, elementCount, Object[].class); //用Arrays.copyOf()方法转换类型。 &#125; 3.3.Vector(int initialCapacity)使用指定的初始容量和等于零的容量增量构造一个空向量。123public Vector(int initialCapacity) &#123; this(initialCapacity, 0);//这里的this其实调用的是Vector(int initialCapacity, int capacityIncrement)方法 &#125; 3.4.Vector(int initialCapacity, int capacityIncrement) 我们从前面知道，无参构造和单参构造本质上都调用的是这个方法。我们来具体了解一下。使用指定的初始容量和容量增量构造一个空的向量。1234567891011//initialCapacity指的是初始容量。//capacityIncrement指的是扩容容量。 public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); this.elementData = new Object[initialCapacity]; //从这里可以看出Vector底层也是数组实现的。 this.capacityIncrement = capacityIncrement; &#125; 4. Vector常用方法 4.1.Vector最初的方法 a.addElement(E obj)将指定的组件添加到此向量的末尾，将其大小增加 1。如果向量的大小比容量大，则增大其容量。 12345public synchronized void addElement(E obj) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = obj; &#125; 从addElement方法中有ensureCapacityHelper(elementCount + 1);我们大致可以推测出这一步是用来扩容的。接着看这个方法：12345 private void ensureCapacityHelper(int minCapacity) &#123; // overflow-conscious code检测是否大于数组长度 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; 123456789101112131415 private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); //注意：这是和ArrayList不同的地方，这个的自动扩容是直接增加一个oldCapacity，也就是扩大了一倍。 /*第一个判断是怕扩容的数组长度还是太小，就用minCapacity 来进行对数组的扩张。第二个判断是如果扩张1倍太大或者是我们所需的空间大小minCapacity太大，则进行Integer.MAX_VALUE来进行扩张。*/ if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 2.elementAt(int index)返回指定索引处的组件。 其实这个方法就是和我们之前使用的get方法很相似。源码很简单，就是说先进行一个index的有效位检验，如果正确在进入elementData(int index)方法，直接取数组的数据。1234567891011 public synchronized E elementAt(int index) &#123; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt;= " + elementCount); &#125; return elementData(index); &#125;//---------------------------------------------E elementData(int index) &#123; return (E) elementData[index]; &#125; 3. elements()返回此向量的组件的枚举。返回的 Enumeration 对象将生成此向量中的所有项。生成的第一项为索引 0 处的项，然后是索引 1 处的项，依此类推。其实我们仔细观察就可以发现，这个和我们之前遍历时候用的Iterator很相似。123456789101112131415161718public Enumeration&lt;E&gt; elements() &#123; return new Enumeration&lt;E&gt;() &#123; int count = 0; public boolean hasMoreElements() &#123; return count &lt; elementCount; &#125; public E nextElement() &#123; synchronized (Vector.this) &#123; if (count &lt; elementCount) &#123; return elementData(count++); &#125; &#125; throw new NoSuchElementException("Vector Enumeration"); &#125; &#125;; &#125; Enumeration是一个接口，直接在方法里面实现。从中我们可以看到hasMoreElements（）和nextElement（）方法。下来举个例子来体会一下。12345678910111213141516171819public static void main(String[] args) &#123; /* * 对Vector的一个简单使用 * */ Vector v=new Vector (); v.addElement ("hello"); //--------------&gt;add() v.addElement ("world"); v.addElement ("java"); System.out.println (v.elementAt (1));//下标从0开始 //--------------&gt;get() System.out.println ("-----------------"); Enumeration elements = v.elements (); //--------------&gt;Iterator() while (elements.hasMoreElements ())&#123; //--------------&gt;hasNext() Object o = elements.nextElement (); //--------------&gt;next() System.out.println (o); &#125; &#125; 4.2.Vector JDK1.2之后的方法 JDK1.2之后出来的方法，为什么有之前的方法还要再加入新方法？ JDK1.2升级的原因无非有三个：1.安全问题2.效率问题3.简化书写 1.add 添加元素的方法实现比较简单：直接在数组的后一个位置添加即可，不过在添加元素之前需要检查数组中是否已满，如果已满，则扩容。 123456789101112131415161718192021222324252627282930313233343536 //添加一个元素到末尾，数组长度+1public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true; &#125; //添加一个元素到指定位置。public void add(int index, E element) &#123; insertElementAt(element, index); &#125;/*insertElementAt()方法，先进行有效位检验，然后在使用ensureCapacityHelper更改数组长度+1，在使用System.arraycopy()方法，这个方法的具体解析，可以去看ArrayList的源码，里面有分析。*/public synchronized void insertElementAt(E obj, int index) &#123; modCount++; if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt; " + elementCount); &#125; ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++; &#125; // public synchronized boolean addAll(Collection&lt;? extends E&gt; c) &#123; modCount++; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityHelper(elementCount + numNew); System.arraycopy(a, 0, elementData, elementCount, numNew); elementCount += numNew; return numNew != 0; &#125; 2.get 返回向量中指定位置的元素。 先进行有效位检验，直接从数组取相应下标元素。类似于elementAt（int index） 123456public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index); &#125; set4用指定的元素替换此向量中指定位置处的元素。 Vector底层使用的是数组，所以这就相当于对数组的操作。先进行有效位检验，然后把指定下标的元素改成element。 12345678public synchronized E set(int index, E element) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; 4.remove remove方法其实和ArrayList里面的方法区别不大。我们主要来看两个方法就可以了。 4.4.1.remove(int index) 先进行有效位检测，然后取出index下标的元素，在计算index元素之后的长度，最后使用 System.arraycopy()直接把index位置跳过，再把elementData[]最后一位元素置为null,让垃圾回收器将其回收。1234567891011121314public synchronized E remove(int index) &#123; modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return oldValue; &#125; 4.4.2.remove(Object o) 删除指定元素。其实这个也特别简单，remove(Object o)底层调用了removeElement(o)方法。removeElement(o)的实现就是先把当前元素的位置下标取出来，然后有了下标就可以使用remove(int index)方法了。12345678910111213public boolean remove(Object o) &#123; return removeElement(o); &#125;//-------------------------------- public synchronized boolean removeElement(Object obj) &#123; modCount++; int i = indexOf(obj); if (i &gt;= 0) &#123; removeElementAt(i); return true; &#125; return false; &#125; 5. 总结Vector里面是基于数组来实现的需要注意的是：Vector是线程安全的，因此，在多线程并发中是不需要使用额外同步的，而ArrayList实现基本与Vector一样，但是区别是：ArrayList是线程不安全的，在多线程并发时，需要我们进行额外的同步。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java源码</tag>
      </tags>
  </entry>
</search>
