<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[初识NIO一]]></title>
    <url>%2F2018%2F06%2F22%2FNIO%2F</url>
    <content type="text"><![CDATA[NIO概述Java NIO（New IO） 是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同， NIO支持面向缓冲区的、基于通道的IO操作。 NIO将以更加高效的方式进行文件的读写操作。 JDK之后的NIO：也叫做NIO2（BIO） Path：路径（与平台无关） Paths：有一个静态方法返回路径（返回Path的静态方法） public static Path get(URI uri); Files：提供静态方法（操作文件的工具类） public static long copy(Path source, OutputStream out) 将文件中的所有字节复制到输出流。 public static Path write(Path path, Iterable&lt;? extends CharSequence&gt; lines, Charset cs, OpenOption... options) 将文本行写入文件。 NIO与IO区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 通道和缓冲区Java NIO系统的核心在于：通道(Channel)和(Buffer)。通道表示打开到 IO 设备(例如：套接字)的连接。若需要使用 NIO 系统，需用于连接 IO 设备的通道以及用于容纳数据区。然后操作缓冲区，对数据进行处理 简而言之， Channel 负责传输， Buffer 负责存储 NIO缓冲区（Buffer） 缓冲区（Buffer） ：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类 Java NIO 中的 Buffer 主要用于与 NIO 通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的 Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类：  ByteBuffer  CharBuffer  ShortBuffer  IntBuffer  LongBuffer  FloatBuffer  DoubleBuffer 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。 都是通过如下方法获取一个 Buffer对象：static XxxBuffer allocate(int capacity) : 创建一个容量为 capacity 的 XxxBuffer 对象 Buffer 中的重要概念： 容量 (capacity) ： 表示 Buffer 最大数据容量，缓冲区容量不能为负，并且创建后不能更改。 限制 (limit)： 第一个不应该读取或写入的数据的索引，即位于 limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 位置 (position)： 下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制 标记 (mark)与重置 (reset)： 标记是一个索引，通过 Buffer 中的 mark() 方法指定 Buffer 中一个特定的 position，之后可以通过调用 reset() 方法恢复到这个 position 并且 0 &lt; mark &lt;= position &lt;=limit &lt;= capacity NIO通道(Channel)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>NIO</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql必知必会（连接，查询，排序）]]></title>
    <url>%2F2018%2F06%2F10%2FMysql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%EF%BC%88%E8%BF%9E%E6%8E%A5%EF%BC%8C%E6%A3%80%E7%B4%A2%EF%BC%8C%E6%8E%92%E5%BA%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Mysql必知必会（连接，检索，排序）分别对应Mysql必知必会3,4,5章节的内容。下面做简单的示例。 连接数据库和进入 连接数据123456mysql -u ben //以ben用户进入数据库 mysql -uroot -proot -h localhost -P 3306 //以root用户，root密码，本地ip，端口号3306进入mysql。mysql -uroot -proot //默认本地，3306登录。 登录成功页面： 选择数据库 SHOW DATABASES; //显示所有表空间1234567891011121314151617mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || demo || exam || how2java || jh || magic || mysql || performance_schema || root || ssh || test |+--------------------+11 rows in set (0.00 sec) USE jh //使用jh数据库表空间 12mysql&gt; use jh;Database changed show tables; //显示jh数据库中有哪些表123456789101112131415mysql&gt; show tables;+--------------+| Tables_in_jh |+--------------+| category || customers || knowledge || orderitems || orders || productnotes || products || user || vendors |+--------------+9 rows in set (0.00 sec) SHOW COLUMNS FROM customers//查看表结构123456789101112131415mysql&gt; SHOW COLUMNS FROM customers;+--------------+-----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+-----------+------+-----+---------+----------------+| cust_id | int(11) | NO | PRI | NULL | auto_increment || cust_name | char(50) | NO | | NULL | || cust_address | char(50) | YES | | NULL | || cust_city | char(50) | YES | | NULL | || cust_state | char(5) | YES | | NULL | || cust_zip | char(10) | YES | | NULL | || cust_country | char(50) | YES | | NULL | || cust_contact | char(50) | YES | | NULL | || cust_email | char(255) | YES | | NULL | |+--------------+-----------+------+-----+---------+----------------+9 rows in set (0.01 sec) 其实还有一些数据库的show语句： SHOW STATUS; //显示服务器状态 SHOW CREATE DATABASE || SHOW CREATE TABLE; //显示特定数据库或表的语句 SHOW GRANTS; //显示授权用户的安全权限 SHOW ERROR || SHOW WARNINGS; //显示服务器错误和警告 DESC product;查看表结构1234567891011mysql&gt; DESC products;+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| prod_id | char(10) | NO | PRI | NULL | || vend_id | int(11) | NO | MUL | NULL | || prod_name | char(255) | NO | | NULL | || prod_price | decimal(8,2) | NO | | NULL | || prod_desc | text | YES | | NULL | |+------------+--------------+------+-----+---------+-------+5 rows in set (0.01 sec) 数据库的查询select语句是用来从数据库中查询的语句，也是最重要的语句。简单的说一下sql语句的一些要求: 结束sql语句，用(;)号隔开；多条语句也是。 SQL语句不区分大小写，但是尽量在SQL关键字的时候使用大写，便于阅读和区分。 处理SQL语句的时候，其中所有的空格都被忽略，可以把所有语句写在一行，但是便于阅读，尽量分行写。检索单个列 SELECT prod_name FROM products; 这个语句就是检索products中的 prod_name 这一列。12345678910111213141516171819+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed || Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 检索多个列 select prod_id,prod_name,prod_price from products; 这个语句就是检索products中的 prod_name,prod_name,prod_price 三列。1234567891011121314151617181920mysql&gt; select prod_id,prod_name,prod_price from products;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| ANV01 | .5 ton anvil | 5.99 || ANV02 | 1 ton anvil | 9.99 || ANV03 | 2 ton anvil | 14.99 || DTNTR | Detonator | 13.00 || FB | Bird seed | 10.00 || FC | Carrots | 2.50 || FU1 | Fuses | 3.42 || JP1000 | JetPack 1000 | 35.00 || JP2000 | JetPack 2000 | 55.00 || OL1 | Oil can | 8.99 || SAFE | Safe | 50.00 || SLING | Sling | 4.49 || TNT1 | TNT (1 stick) | 2.50 || TNT2 | TNT (5 sticks) | 10.00 |+---------+----------------+------------+14 rows in set (0.00 sec) 检索所有列这个使用了通配符（*），这个代表所有的意思。 select * from products; 检索products的所有信息。1234567891011121314151617181920mysql&gt; select * from products;+---------+---------+----------------+------------+----------------------------------------------------------------+| prod_id | vend_id | prod_name | prod_price | prod_desc |+---------+---------+----------------+------------+----------------------------------------------------------------+| ANV01 | 1001 | .5 ton anvil | 5.99 | .5 ton anvil, black, complete with handy hook || ANV02 | 1001 | 1 ton anvil | 9.99 | 1 ton anvil, black, complete with handy hook and carrying case || ANV03 | 1001 | 2 ton anvil | 14.99 | 2 ton anvil, black, complete with handy hook and carrying case || DTNTR | 1003 | Detonator | 13.00 | Detonator (plunger powered), fuses not included || FB | 1003 | Bird seed | 10.00 | Large bag (suitable for road runners) || FC | 1003 | Carrots | 2.50 | Carrots (rabbit hunting season only) || FU1 | 1002 | Fuses | 3.42 | 1 dozen, extra long || JP1000 | 1005 | JetPack 1000 | 35.00 | JetPack 1000, intended for single use || JP2000 | 1005 | JetPack 2000 | 55.00 | JetPack 2000, multi-use || OL1 | 1002 | Oil can | 8.99 | Oil can, red || SAFE | 1003 | Safe | 50.00 | Safe with combination lock || SLING | 1003 | Sling | 4.49 | Sling, one size fits all || TNT1 | 1003 | TNT (1 stick) | 2.50 | TNT, red, single stick || TNT2 | 1003 | TNT (5 sticks) | 10.00 | TNT, red, pack of 10 sticks |+---------+---------+----------------+------------+----------------------------------------------------------------+14 rows in set (0.00 sec) 检索不同行比如我们要查询的数据中，有多个重复的数据，我们只想要不同的数据。 select vend_id from products; 1234567891011121314151617181920mysql&gt; select vend_id from products;+---------+| vend_id |+---------+| 1001 || 1001 || 1001 || 1002 || 1002 || 1003 || 1003 || 1003 || 1003 || 1003 || 1003 || 1003 || 1005 || 1005 |+---------+14 rows in set (0.00 sec) 很明显很多数据是无用的。我们现在要来剔除这些重复。我们要使用这个关键字：distinct；要注意的是不能同时使用distinct限制多行， select distinct vend_id，prod_price from products; select distinct vend_id from products;除非两列都相同，否则都会被查出来。 12345678910mysql&gt; select distinct vend_id from products;+---------+| vend_id |+---------+| 1001 || 1002 || 1003 || 1005 |+---------+4 rows in set (0.00 sec) 限制结果(分页) select prod_name from products limit 0,5; 1234567891011mysql&gt; select prod_name from products limit 0,5;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed |+--------------+5 rows in set (0.00 sec) 其中 0是开始位置，5是显示长度。 数据排序排序数据 select prod_name from products order by prod_name; 把查询到的数据按照prod_name排序。1234567891011121314151617181920mysql&gt; select prod_name from products order by prod_name;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Bird seed || Carrots || Detonator || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 多个序列排序 select prod_id,prod_price,prod_name from products order by prod_price,prod_name; 这个例子其实要这样子理解，就是只有在prod_price有相同的情况下，然后取按照prod_name排序。 1234567891011121314151617181920mysql&gt; select prod_id,prod_price,prod_name from products order by prod_price,prod_name;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| FC | 2.50 | Carrots || TNT1 | 2.50 | TNT (1 stick) || FU1 | 3.42 | Fuses || SLING | 4.49 | Sling || ANV01 | 5.99 | .5 ton anvil || OL1 | 8.99 | Oil can || ANV02 | 9.99 | 1 ton anvil || FB | 10.00 | Bird seed || TNT2 | 10.00 | TNT (5 sticks) || DTNTR | 13.00 | Detonator || ANV03 | 14.99 | 2 ton anvil || JP1000 | 35.00 | JetPack 1000 || SAFE | 50.00 | Safe || JP2000 | 55.00 | JetPack 2000 |+---------+------------+----------------+14 rows in set (0.00 sec) 正序，倒序 select prod_id,prod_price,prod_name from products order by prod_price DESC; 其中DESC是倒序的意思，升序就是ASC，但是ASC没有多大作用，因为默认就是ASC的1234567891011121314151617181920mysql&gt; select prod_id,prod_price,prod_name from products order by prod_price DESC;+---------+------------+----------------+| prod_id | prod_price | prod_name |+---------+------------+----------------+| JP2000 | 55.00 | JetPack 2000 || SAFE | 50.00 | Safe || JP1000 | 35.00 | JetPack 1000 || ANV03 | 14.99 | 2 ton anvil || DTNTR | 13.00 | Detonator || TNT2 | 10.00 | TNT (5 sticks) || FB | 10.00 | Bird seed || ANV02 | 9.99 | 1 ton anvil || OL1 | 8.99 | Oil can || ANV01 | 5.99 | .5 ton anvil || SLING | 4.49 | Sling || FU1 | 3.42 | Fuses || FC | 2.50 | Carrots || TNT1 | 2.50 | TNT (1 stick) |+---------+------------+----------------+14 rows in set (0.00 sec) 排序小结排序是不区分大小写的，对于sql语句来说，A和a的一样的。其实可以用order by 和 limit混合来使用。比如，查询最高价格。 select * from products order by prod_price DESC limit 1; 1234567mysql&gt; select * from products order by prod_price DESC limit 1;+---------+---------+--------------+------------+-------------------------+| prod_id | vend_id | prod_name | prod_price | prod_desc |+---------+---------+--------------+------------+-------------------------+| JP2000 | 1005 | JetPack 2000 | 55.00 | JetPack 2000, multi-use |+---------+---------+--------------+------------+-------------------------+1 row in set (0.00 sec)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解SQL]]></title>
    <url>%2F2018%2F06%2F10%2FMysql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%EF%BC%881%2C2%E7%AB%A0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[了解SQL1.DBMS数据库管理系统 数据库（database） 保存有组织的数据容器。DBMS是操纵和创建数据库的软件，不能直接访问数据库，是通过DBMS去访问。 表（table） 某种特定类型数据的结构化清单。一个结构化的文件，用来存储某种特定类型的数据。 模式（schema） 关于数据库和表的布局以及特征的信息 列（column） 表中的一个字段。所有的表都是由多个或一个列组成的。可以把它想象成一个网格，网格中每个列存储着一条特定的信息。 数据类型（datatype） 所容许的数据类型，它限制列中存储的数据。 行（row） 表中的一个记录。表中的行数也为记录的总数。 主键（primary key） 一列（或一组列），其值能够唯一区分表中的每个行。 ++主键的规范++： 任意两行都不能具有相同的主键值。每个行都必须具有一个主键值（主键不允许为NULL）。 2.什么是SQL?SQL是结构化查询语言（Structured Query Language），是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件的扩展名。SQL的优点： SQL不是某个特定的数据库专用的语言，几乎所有的DBMS都支持SQL。 SQL简单易学，语句描述性很强。 SQL看上去很简单，但是是一个强有力的语言，可以进行很复杂的数据库操作。 3.MySQL简述 MySQL是一个小型关系型数据库管理系统，开发者为瑞典MySQL AB公司，现在已经被Sun公司收购，支持FreeBSD、Linux、MAC、Windows等多种操作系统与其他的大型数据库例如Oracle、DB2、SQL Server等相比功能稍弱一些。其特点有： 1、可以处理拥有上千万条记录的大型数据； 2、支持常见的SQL语句规范； 3、可移植行高，安装简单小巧； 4、良好的运行效率，有丰富信息的网络支持； 5、调试、管理，优化简单（相对其他大型数据库）。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap的源码解析]]></title>
    <url>%2F2018%2F06%2F08%2Fhashmap%2F</url>
    <content type="text"><![CDATA[HashMap的源码解析HashMap的概述HashMap是常用的Java集合之一，是基于哈希表的Map接口的实现。由于HashMap不是线程安全的，如果想要线程安全，可以使用ConcurrentHashMap代替。 API里面给的解释是： 基于哈希表的 Map 接口的实现。此实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap的继承体系我们要了解一个类，首先要了解一下他的继承结构，，才能更好的理解这个类。 123public class HashMap&lt;K,V&gt;extends AbstractMap&lt;K,V&gt;implements Map&lt;K,V&gt;,Cloneable, Serializable 我们可以看一下继承图。这里我们要注意HashMap和Hashtable的继承是不一样的，Hashtable继承的是Dictionary。 大概介绍一下HashMap和Hashtable， HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 HashMap的数据结构从结构实现来讲，HashMap 是数组+链表+红黑树给大家一个图可以更加直观的了解其结构 我们其实还要想，到底是在底层是怎样存储的？为什么这样存，或者说有什么优点？ 我们能从上图看出来，首先是一个数组的存储,查看源码可知，有一个很重要的数组，Node&lt;K,V&gt;[] table，很明显，它是一个Node数组，我们来看一下Node的结构。123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 2.HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码：1hs.put(1,&quot;magic&quot;); 系统将调用”1”这个key的hashCode()方法得到其hashCode 值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。不会都加到一个下标下面的链表去。保证每一个的分散性、均匀性。要做到雨露均沾。 如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。 那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的==Hash算法==和==扩容机制==。 在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子 int modCount; int size; 12345678910111213141516171819202122在 HashMap 中定义了几个常量:static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64; 依次解释一下上面的变量：1. DEFAULT_INITIAL_CAPACITY: 初始容量，也就是默认会创建 16 个箱子，箱子的个数不能太多或太少。如果太少，很容易触发扩容，如果太多，遍历哈希表会比较慢。2. MAXIMUM_CAPACITY:哈希表最大容量，一般情况下只要内存够用，哈希表不会出现问题。3. DEFAULT_LOAD_FACTOR:默认的负载因子。因此初始情况下，当键值对的数量大于 16 * 0.75 = 12 时，就会触发扩容。4. TREEIFY_THRESHOLD:上文说过，如果哈希函数不合理，即使扩容也无法减少箱子中链表的长度，因此 Java 的处理方案是当链表太长时，转换成红黑树。这个值表示当某个箱子中，链表长度大于 8 时，有可能会转化成树。5. UNTREEIFY_THRESHOLD:在哈希表扩容时，如果发现链表长度小于 6，则会由树重新退化为链表。6. MIN_TREEIFY_CAPACITY:在转变成树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换。这是为了避免在哈希表建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。 首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，++扩容后的HashMap容量是之前容量的两倍++。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量（数组中现有的元素）。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中，++哈希桶数组table的长度length大小必须为2的n次方(一定是合数)++，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考http://blog.csdn.net/liuqiyao_01/article/details/14475159，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，==在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。==而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考http://blog.csdn.net/v_july_v/article/details/6105630。 HashMap的功能实现-方法HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。 1. 确定哈希桶数组索引位置不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):12345678910111213141516方法一：static final int hash(Object key) &#123; //jdk1.8 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//jdk1.7static int hash(int h) &#123; h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。下面举例说明下，n为table的长度。 2. 分析HashMap的put方法HashMap的put方法执行过程可以通过下图来理解.①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); &#125; //从put()进入putVal(hash(key), key, value, false, true)；final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 3. 扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。12345678910111213void resize(int newCapacity) &#123; //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor);//修改阈值 &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125;&#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，++所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。++看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，++由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。++有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold初始容量被放入阈值 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults零初始阈值表示使用默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 线程安全性(待深入)在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)： 1234567891011121314151617181920public class HashMapInfiniteLoop &#123; private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); public static void main(String[] args) &#123; map.put(5， &quot;C&quot;); new Thread(&quot;Thread1&quot;) &#123; public void run() &#123; map.put(7, &quot;B&quot;); System.out.println(map); &#125;; &#125;.start(); new Thread(&quot;Thread2&quot;) &#123; public void run() &#123; map.put(3, &quot;A); System.out.println(map); &#125;; &#125;.start(); &#125; &#125; 其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。 线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。 JDK1.8与JDK1.7的性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。 Hash较均匀的情况为了便于测试，我们先写一个类Key，如下： 123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125; 这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下： 123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125; 现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下： 1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125; 在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下： 通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。 Hash极不均匀的情况假设我们又一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下：123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125; 仍然执行main方法，得出的结果如下表所示：从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。 测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。 小结(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。 (2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 (3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。 (4) JDK1.8引入红黑树大程度优化了HashMap的性能。 (5) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于String的理解]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%85%B3%E4%BA%8EString%E7%B1%BB%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[关于下面的代码，为什么结果为true？在我们的想法里，String是一个引用类型，为什么对象可以相等？12345678910111213141516package cn.lq.demo;public class StringDemo &#123; /** * @author magic_jh * @version 1.1.0 */ public static void main(String[] args) &#123; String s1="helloworld"; String s2="helloworld"; String s3=new String("helloworld"); System.out.println(s1==s2);//true System.out.println(s1==s3);//false &#125;&#125; 其实可以看一下内存的分配，就一目了然了。 从图中可以看出其实s1和s2指向的不是堆内存，而是方法区的字符常量池，所以我们知道==比的是地址值，s1,s2指向的是同一个地址，肯定结果为true。我们现在来看s3，s3使用的是构造方法，它就在堆内存开辟了一个空间，其中的”helloworld”还是来自于字符常量池。所以s3指向的是堆内存中的地址，最后与s1比较的是s3指向的地址是堆内存的地址，所以为false。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的操作示例]]></title>
    <url>%2F2018%2F06%2F06%2Fjh0904%2F</url>
    <content type="text"><![CDATA[magic_jh第一次测试三级标题 列表1 列表2 a子列表 b子列表 c子列表 列表3 列表4 jh 字体是斜体 字体加粗 123public static void main(String[] args)&#123;asdas&#125; 我的内容是引用]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>导航</tag>
        <tag>分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vector的源码解析]]></title>
    <url>%2F2018%2F06%2F06%2FVector%E7%9A%84%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Vector源码解析1. Vector概述及继承体系Vector 类可以实现可增长的对象数组。与数组一样，它包含可以使用整数索引进行访问的组件。与新 collection 实现不同，Vector 是同步的。 看一下Vector的继承体系：12public class Vector&lt;E&gt;extends AbstractList&lt;E&gt;implements List&lt;E&gt;, RandomAccess, Cloneable, Serializable RandomAccess接口是在源码中的注释如下： Marker interface used by List implementations to indicate that theysupport fast (generally constant time) random access. 翻译下就是：这是一个标记性的接口，谁实现了这个接口就表明他具有快速随机访问的能力。 2. Vector属性capacityIncrement：自动扩容的大小，即当数组满了之后，就添加capacityIncrement个空间装载元素，如果capacityIncrement&lt;=0,则扩容时就扩容到目前Vector容量的两倍。 elementCount:记录数组中数据的个数。 elementData:数组，因为Vector底层也是数组存储的，所以用这个来存储数据。 123protected int capacityIncrement; //扩容大小protected int elementCount; //数组数据条数protected Object[] elementData; //数组 3. Vector构造方法 Vector构造方法有四个构造方法 3.1.Vector()构造一个空向量，使其内部数据数组的大小为 10，其标准容量增量为零。123public Vector() &#123; this(10);//这里的this调用的是Vector(int initialCapacity) 方法 &#125; 3.2.Vector(Collection &lt;\?extends E&gt; c)构造一个包含指定 collection 中的元素的向量，这些元素按其 collection 的迭代器返回元素的顺序排列。123456789 public Vector(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) //c.toArray可能（不正确）不返回Object []（参见6260652） if (elementData.getClass() != Object[].class)`````` elementData = Arrays.copyOf(elementData, elementCount, Object[].class); //用Arrays.copyOf()方法转换类型。 &#125; 3.3.Vector(int initialCapacity)使用指定的初始容量和等于零的容量增量构造一个空向量。123public Vector(int initialCapacity) &#123; this(initialCapacity, 0);//这里的this其实调用的是Vector(int initialCapacity, int capacityIncrement)方法 &#125; 3.4.Vector(int initialCapacity, int capacityIncrement) 我们从前面知道，无参构造和单参构造本质上都调用的是这个方法。我们来具体了解一下。使用指定的初始容量和容量增量构造一个空的向量。1234567891011//initialCapacity指的是初始容量。//capacityIncrement指的是扩容容量。 public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); this.elementData = new Object[initialCapacity]; //从这里可以看出Vector底层也是数组实现的。 this.capacityIncrement = capacityIncrement; &#125; 4. Vector常用方法 4.1.Vector最初的方法 a.addElement(E obj)将指定的组件添加到此向量的末尾，将其大小增加 1。如果向量的大小比容量大，则增大其容量。 12345public synchronized void addElement(E obj) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = obj; &#125; 从addElement方法中有ensureCapacityHelper(elementCount + 1);我们大致可以推测出这一步是用来扩容的。接着看这个方法：12345 private void ensureCapacityHelper(int minCapacity) &#123; // overflow-conscious code检测是否大于数组长度 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; 123456789101112131415 private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); //注意：这是和ArrayList不同的地方，这个的自动扩容是直接增加一个oldCapacity，也就是扩大了一倍。 /*第一个判断是怕扩容的数组长度还是太小，就用minCapacity 来进行对数组的扩张。第二个判断是如果扩张1倍太大或者是我们所需的空间大小minCapacity太大，则进行Integer.MAX_VALUE来进行扩张。*/ if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 2.elementAt(int index)返回指定索引处的组件。 其实这个方法就是和我们之前使用的get方法很相似。源码很简单，就是说先进行一个index的有效位检验，如果正确在进入elementData(int index)方法，直接取数组的数据。1234567891011 public synchronized E elementAt(int index) &#123; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt;= " + elementCount); &#125; return elementData(index); &#125;//---------------------------------------------E elementData(int index) &#123; return (E) elementData[index]; &#125; 3. elements()返回此向量的组件的枚举。返回的 Enumeration 对象将生成此向量中的所有项。生成的第一项为索引 0 处的项，然后是索引 1 处的项，依此类推。其实我们仔细观察就可以发现，这个和我们之前遍历时候用的Iterator很相似。123456789101112131415161718public Enumeration&lt;E&gt; elements() &#123; return new Enumeration&lt;E&gt;() &#123; int count = 0; public boolean hasMoreElements() &#123; return count &lt; elementCount; &#125; public E nextElement() &#123; synchronized (Vector.this) &#123; if (count &lt; elementCount) &#123; return elementData(count++); &#125; &#125; throw new NoSuchElementException("Vector Enumeration"); &#125; &#125;; &#125; Enumeration是一个接口，直接在方法里面实现。从中我们可以看到hasMoreElements（）和nextElement（）方法。下来举个例子来体会一下。12345678910111213141516171819public static void main(String[] args) &#123; /* * 对Vector的一个简单使用 * */ Vector v=new Vector (); v.addElement ("hello"); //--------------&gt;add() v.addElement ("world"); v.addElement ("java"); System.out.println (v.elementAt (1));//下标从0开始 //--------------&gt;get() System.out.println ("-----------------"); Enumeration elements = v.elements (); //--------------&gt;Iterator() while (elements.hasMoreElements ())&#123; //--------------&gt;hasNext() Object o = elements.nextElement (); //--------------&gt;next() System.out.println (o); &#125; &#125; 4.2.Vector JDK1.2之后的方法 JDK1.2之后出来的方法，为什么有之前的方法还要再加入新方法？ JDK1.2升级的原因无非有三个：1.安全问题2.效率问题3.简化书写 1.add 添加元素的方法实现比较简单：直接在数组的后一个位置添加即可，不过在添加元素之前需要检查数组中是否已满，如果已满，则扩容。 123456789101112131415161718192021222324252627282930313233343536 //添加一个元素到末尾，数组长度+1public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true; &#125; //添加一个元素到指定位置。public void add(int index, E element) &#123; insertElementAt(element, index); &#125;/*insertElementAt()方法，先进行有效位检验，然后在使用ensureCapacityHelper更改数组长度+1，在使用System.arraycopy()方法，这个方法的具体解析，可以去看ArrayList的源码，里面有分析。*/public synchronized void insertElementAt(E obj, int index) &#123; modCount++; if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt; " + elementCount); &#125; ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++; &#125; // public synchronized boolean addAll(Collection&lt;? extends E&gt; c) &#123; modCount++; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityHelper(elementCount + numNew); System.arraycopy(a, 0, elementData, elementCount, numNew); elementCount += numNew; return numNew != 0; &#125; 2.get 返回向量中指定位置的元素。 先进行有效位检验，直接从数组取相应下标元素。类似于elementAt（int index） 123456public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index); &#125; set4用指定的元素替换此向量中指定位置处的元素。 Vector底层使用的是数组，所以这就相当于对数组的操作。先进行有效位检验，然后把指定下标的元素改成element。 12345678public synchronized E set(int index, E element) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; 4.remove remove方法其实和ArrayList里面的方法区别不大。我们主要来看两个方法就可以了。 4.4.1.remove(int index) 先进行有效位检测，然后取出index下标的元素，在计算index元素之后的长度，最后使用 System.arraycopy()直接把index位置跳过，再把elementData[]最后一位元素置为null,让垃圾回收器将其回收。1234567891011121314public synchronized E remove(int index) &#123; modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return oldValue; &#125; 4.4.2.remove(Object o) 删除指定元素。其实这个也特别简单，remove(Object o)底层调用了removeElement(o)方法。removeElement(o)的实现就是先把当前元素的位置下标取出来，然后有了下标就可以使用remove(int index)方法了。12345678910111213public boolean remove(Object o) &#123; return removeElement(o); &#125;//-------------------------------- public synchronized boolean removeElement(Object obj) &#123; modCount++; int i = indexOf(obj); if (i &gt;= 0) &#123; removeElementAt(i); return true; &#125; return false; &#125; 5. 总结Vector里面是基于数组来实现的需要注意的是：Vector是线程安全的，因此，在多线程并发中是不需要使用额外同步的，而ArrayList实现基本与Vector一样，但是区别是：ArrayList是线程不安全的，在多线程并发时，需要我们进行额外的同步。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java源码</tag>
      </tags>
  </entry>
</search>
